import streamlit as st
import os
from openai import OpenAI
from PIL import Image
import io
import base64

# OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ç”»åƒèªè­˜ã‚¢ãƒ—ãƒª",
    page_icon="ğŸ–¼ï¸",
    layout="centered"
)

st.title("ğŸ–¼ï¸ ç”»åƒèªè­˜ã‚¢ãƒ—ãƒª")
st.markdown("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€AIã«èªè­˜ã•ã›ã¦ã¿ã¾ã—ã‚‡ã†")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§èªè­˜ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ
recognition_mode = st.sidebar.radio(
    "èªè­˜ãƒ¢ãƒ¼ãƒ‰",
    ["ç”»åƒã®èª¬æ˜", "ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º", "ãƒ†ã‚­ã‚¹ãƒˆèªè­˜", "ã‚«ã‚¹ã‚¿ãƒ è³ªå•"]
)

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†
uploaded_file = st.file_uploader("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "jpeg", "png", "gif", "webp"])

if uploaded_file:
    # ç”»åƒã®è¡¨ç¤º
    image = Image.open(uploaded_file)
    st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)

    # ç”»åƒã®ãƒ—ãƒªãƒ“ãƒ¥ãƒ¼ã‚µã‚¤ã‚ºï¼ˆè¡¨ç¤ºç”¨ï¼‰
    display_image = image.copy()
    display_image.thumbnail((200, 200))

    # åˆ†æãƒœã‚¿ãƒ³
    if st.button("ğŸ” ç”»åƒã‚’åˆ†æ", key="analyze_button"):
        with st.spinner("åˆ†æä¸­..."):
            try:
                # ç”»åƒã‚’Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
                buffered = io.BytesIO()
                image.save(buffered, format="PNG")
                image_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

                # èªè­˜ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­å®š
                prompts = {
                    "ç”»åƒã®èª¬æ˜": "ã“ã®ç”»åƒã®è©³ç´°ãªèª¬æ˜ã‚’ã—ã¦ãã ã•ã„ã€‚ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã‚‹ã‹ã€ã©ã‚“ãªçŠ¶æ³ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
                    "ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º": "ã“ã®ç”»åƒã«å«ã¾ã‚Œã‚‹ã™ã¹ã¦ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆç‰©ä½“ï¼‰ã‚’æ¤œå‡ºã—ã€ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚å„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
                    "ãƒ†ã‚­ã‚¹ãƒˆèªè­˜": "ã“ã®ç”»åƒã«å«ã¾ã‚Œã‚‹ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦ã€ãã®ã¾ã¾è»¢è¨˜ã—ã¦ãã ã•ã„ã€‚ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚",
                    "ã‚«ã‚¹ã‚¿ãƒ è³ªå•": "ã“ã®ç”»åƒã«ã¤ã„ã¦ã€ä½•ã‹ç‰¹å¾´çš„ãªã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿæ•™ãˆã¦ãã ã•ã„ã€‚"
                }

                prompt = prompts[recognition_mode]

                # GPT-4 Visionã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’åˆ†æ
                response = client.messages.create(
                    model="gpt-4o",
                    max_tokens=1024,
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {
                                    "type": "image",
                                    "source": {
                                        "type": "base64",
                                        "media_type": "image/png",
                                        "data": image_base64
                                    }
                                },
                                {
                                    "type": "text",
                                    "text": prompt
                                }
                            ]
                        }
                    ]
                )

                # çµæœã®è¡¨ç¤º
                st.success("åˆ†æå®Œäº†!")
                st.markdown("### ğŸ“‹ èªè­˜çµæœ")
                st.markdown(response.content[0].text)

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
else:
    st.info("ğŸ“¤ ä¸Šã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("âœ¨ Powered by OpenAI GPT-4 Vision")
