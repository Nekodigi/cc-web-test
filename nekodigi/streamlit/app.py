#!/usr/bin/env python3
"""
Streamlit Image Recognition App
Simple image recognition application using OpenAI's Vision API
"""

import streamlit as st
from openai import OpenAI
from PIL import Image
import io
import os

# Page configuration
st.set_page_config(
    page_title="ğŸ–¼ï¸ ç”»åƒèªè­˜ã‚¢ãƒ—ãƒª",
    page_icon="ğŸ–¼ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS styling
st.markdown("""
    <style>
        .main { max-width: 1000px; }
        .stTitle { font-size: 2.5rem !important; }
        .result-box {
            background-color: #f0f2f6;
            padding: 1.5rem;
            border-radius: 0.5rem;
            border-left: 4px solid #667eea;
        }
        .image-container {
            display: flex;
            justify-content: center;
        }
    </style>
""", unsafe_allow_html=True)

# Title and description
st.title("ğŸ–¼ï¸ ç”»åƒèªè­˜ã‚¢ãƒ—ãƒª")
st.markdown("AIã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚’åˆ†æã—ã¾ã™ã€‚è¤‡æ•°ã®èªè­˜ãƒ¢ãƒ¼ãƒ‰ã‹ã‚‰é¸æŠã§ãã¾ã™ã€‚")

# Initialize OpenAI client
@st.cache_resource
def get_openai_client():
    """Initialize OpenAI client with API key from environment"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("âŒ OPENAI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        st.stop()
    return OpenAI(api_key=api_key)

def analyze_image(image_data: Image.Image, recognition_mode: str, client: OpenAI) -> str:
    """
    Analyze image using OpenAI Vision API

    Args:
        image_data: PIL Image object
        recognition_mode: Type of analysis to perform
        client: OpenAI client instance

    Returns:
        Analysis result string
    """
    # Convert image to base64
    buffer = io.BytesIO()
    image_data.save(buffer, format="PNG")
    image_base64 = __import__('base64').b64encode(buffer.getvalue()).decode()

    # Define prompts for different recognition modes
    prompts = {
        "description": "ã“ã®ç”»åƒã®è©³ç´°ãªèª¬æ˜ã‚’ã—ã¦ãã ã•ã„ã€‚ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã‚‹ã‹ã€ã©ã‚“ãªçŠ¶æ³ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "objects": "ã“ã®ç”»åƒã«å«ã¾ã‚Œã‚‹ã™ã¹ã¦ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆç‰©ä½“ï¼‰ã‚’æ¤œå‡ºã—ã€ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚å„ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«ã¤ã„ã¦ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚",
        "text": "ã“ã®ç”»åƒã«å«ã¾ã‚Œã‚‹ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦ã€ãã®ã¾ã¾è»¢è¨˜ã—ã¦ãã ã•ã„ã€‚ãƒ†ã‚­ã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ãã®æ—¨ã‚’å ±å‘Šã—ã¦ãã ã•ã„ã€‚",
        "custom": "ã“ã®ç”»åƒã«ã¤ã„ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚ç‰¹ã«èˆˆå‘³æ·±ã„ç‰¹å¾´ãŒã‚ã‚Œã°æ•™ãˆã¦ãã ã•ã„ã€‚"
    }

    prompt = prompts.get(recognition_mode, prompts["description"])

    # Call OpenAI Vision API
    response = client.messages.create(
        model="gpt-4o",
        max_tokens=1024,
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": "image/png",
                            "data": image_base64
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }
        ]
    )

    return response.content[0].text

def main():
    """Main application logic"""

    # Get OpenAI client
    client = get_openai_client()

    # Sidebar configuration
    st.sidebar.header("âš™ï¸ è¨­å®š")

    recognition_mode = st.sidebar.selectbox(
        "èªè­˜ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ:",
        [
            ("ç”»åƒã®èª¬æ˜", "description"),
            ("ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º", "objects"),
            ("ãƒ†ã‚­ã‚¹ãƒˆèªè­˜", "text"),
            ("ã‚«ã‚¹ã‚¿ãƒ åˆ†æ", "custom")
        ],
        format_func=lambda x: x[0]
    )
    recognition_mode = recognition_mode[1]

    # Main content area
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ“¤ ç”»åƒã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        uploaded_file = st.file_uploader(
            "ç”»åƒã‚’é¸æŠã—ã¦ãã ã•ã„",
            type=["jpg", "jpeg", "png", "gif", "webp"],
            help="JPG, PNG, GIF, WebPå½¢å¼ã«å¯¾å¿œã—ã¦ã„ã¾ã™"
        )

        if uploaded_file is not None:
            # Display image preview
            image = Image.open(uploaded_file)
            st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_column_width=True)

            # Image info
            st.info(f"ğŸ“ ã‚µã‚¤ã‚º: {image.size[0]}Ã—{image.size[1]} px | å½¢å¼: {image.format}")

    with col2:
        st.subheader("ğŸ“‹ åˆ†æçµæœ")

        if uploaded_file is not None:
            if st.button("ğŸ” ç”»åƒã‚’åˆ†æ", key="analyze_btn", use_container_width=True):
                try:
                    with st.spinner("åˆ†æä¸­..."):
                        image = Image.open(uploaded_file)
                        result = analyze_image(image, recognition_mode, client)

                    st.markdown('<div class="result-box">', unsafe_allow_html=True)
                    st.success("âœ… åˆ†æå®Œäº†")
                    st.markdown(f"**èªè­˜ãƒ¢ãƒ¼ãƒ‰:** {dict([('description', 'ç”»åƒã®èª¬æ˜'), ('objects', 'ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ¤œå‡º'), ('text', 'ãƒ†ã‚­ã‚¹ãƒˆèªè­˜'), ('custom', 'ã‚«ã‚¹ã‚¿ãƒ åˆ†æ')])[recognition_mode]}")
                    st.markdown(f"\n{result}")
                    st.markdown('</div>', unsafe_allow_html=True)

                    # Download result as text
                    st.download_button(
                        label="ğŸ’¾ çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=result,
                        file_name="analysis_result.txt",
                        mime="text/plain",
                        use_container_width=True
                    )

                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        else:
            st.info("ğŸ“¤ å·¦å´ã‹ã‚‰ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

    # Footer
    st.markdown("---")
    st.markdown("""
        <div style="text-align: center; color: #888; font-size: 0.9em;">
            âœ¨ Powered by OpenAI GPT-4 Vision | Streamlit
        </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
